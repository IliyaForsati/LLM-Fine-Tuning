# LLM-Fine-Tuning
This project fine-tunes the GPT-2 model with 124M parameters using the Hugging Face Transformers library.  After fine-tuning, LoRA (Low-Rank Adaptation) is applied with the PEFT library to further train and optimize the model. 
